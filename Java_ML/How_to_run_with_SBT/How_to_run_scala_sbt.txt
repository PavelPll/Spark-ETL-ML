In order to run this Java project on Spark cluster using SBT:

(1) CHECK java 8 or INSTALL it
sudo update-alternatives --config java
java -version
go to java 1.8.*
sudo apt-get install openjdk-8-jre
In my configuration of Hadoop/Spark java 8 is used
 
(2) INSTALL sbt
echo "deb https://repo.scala-sbt.org/scalasbt/debian all main" | sudo tee /etc/apt/sources.list.d/sbt.list
echo "deb https://repo.scala-sbt.org/scalasbt/debian /" | sudo tee /etc/apt/sources.list.d/sbt_old.list
curl -sL "https://keyserver.ubuntu.com/pks/lookup?op=get&search=0x2EE0EA64E40A89B84B2DF73499E82A75642AC823" | sudo apt-key add
sudo apt-get update
sudo apt-get install sbt
sbt -version

(3) RESTART Spark cluster if needed
$SPARK_HOME/sbin/stop-all.sh 
$HADOOP_HOME/sbin/stop-all.sh
$HADOOP_HOME/sbin/start-dfs.sh
$HADOOP_HOME/sbin/start-yarn.sh
$SPARK_HOME/sbin/start-all.sh

(4) Add data file, housing.data, to HDFS
hdfs dfs -put ./housing.data /scala/

(5) CHECK HDFS
hdfs dfs -ls -R /scala
or
http://ip_master:9870/explorer.html#/

(6) COMPILE project
cd ./Spark-ETL-ML/Java_ML/How_to_run_with_SBT
sbt package

(7) RUN Spark job
spark-submit --class "ML" --master yarn --deploy-mode client target/scala-2.12/ml_2.12-1.0.jar

(8) 
USE "--deploy-mode client" to be able to see stdout
or 
USE "--deploy-mode cluster" otherwise
