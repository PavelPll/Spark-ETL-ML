# OBJECTIVE: To get familiar with Spark.
I installed Spark cluster on AWS cloud and demonstrated some its important functionalities. 
* The file spark_installation.txt describes the installation procedure. This is done on top of a Hadoop YARN cluster, installed previously (for details see Hadoop-Hive project in the current git repository: https://github.com/PavelPll/Hadoop-HIVE).  
* The folder ./Scala_ETL contains my example of ETL (Extract Transfer Load) pipeline written in Scala, with a description how to run it on Spark cluster.
* The folder ./Java_ML contains my example of simple machine learning model written in Java, with a description how to run it on Spark cluster.
* An example of data batch processing.
